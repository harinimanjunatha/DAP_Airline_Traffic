{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e58799",
   "metadata": {},
   "source": [
    "# Importing the Data for Air Traffic Cargo Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128e698d",
   "metadata": {},
   "source": [
    "#### Taking the data from the web in json format using API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_call = \"https://data.sfgov.org/api/views/u397-j8nr/rows.json?accessType=DOWNLOAD\"\n",
    "\n",
    "# Get the JSON data from the API\n",
    "response = requests.get(api_call)\n",
    "data = response.json()\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data rows from the JSON data\n",
    "rows = data['data']\n",
    "\n",
    "# Extract the column headers from the JSON data\n",
    "headers = [col['fieldName'] for col in data['meta']['view']['columns']]\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250b8b9e",
   "metadata": {},
   "source": [
    "#### Removing the meta data present in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the metadata fields from the rows as they are not required\n",
    "filtered_rows = []\n",
    "for row in rows:\n",
    "    filtered_row = {headers[idx]: cell for idx, cell in enumerate(row) if not headers[idx].startswith(':')}\n",
    "\n",
    "    filtered_rows.append(filtered_row)\n",
    "\n",
    "# Create a new JSON object without the metadata fields\n",
    "filtered_data = {'data': filtered_rows}\n",
    "filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bbf6fb",
   "metadata": {},
   "source": [
    "#### Obtaining the final data from the filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc114bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = filtered_data['data']\n",
    "final_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc66bb",
   "metadata": {},
   "source": [
    "#### Deleting the data in existing collection in mongodb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import requests\n",
    "#from pymongo import MongoClient \n",
    "#pymongo to connect to an existing document collection\n",
    "from pymongo import MongoClient, InsertOne\n",
    "\n",
    "import requests \n",
    "client = MongoClient('mongodb+srv://arun:nLmzJ6cxxu@cluster0.bqu9sx9.mongodb.net/?retryWrites=true&w=majority')\n",
    "#client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.Test\n",
    "collection = db.test\n",
    "d = collection.delete_many({})\n",
    "print(d.deleted_count, \" documents deleted.\")\n",
    "#test123harini\n",
    "#test123abhijith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=collection.insert_many(final_data)\n",
    "document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83076b32",
   "metadata": {},
   "source": [
    "#### Viewing the data in the Mongodb database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "for Air_cargo in db.test.find():\n",
    "    pp.pprint(Air_cargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = list(collection.find())\n",
    "documents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a91afee",
   "metadata": {},
   "source": [
    "#### Creating csv file of the ATC and adding the obtained data into it by ignoring the id column created in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1473ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a csv file for the obtained json data\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "csvfile = open(\"air_cargo1.csv\",'w', encoding= \"utf-8\")\n",
    "csvfile_writer = csv.writer(csvfile)\n",
    "# ADDING THE HEADER TO CSV FILE\n",
    "csvfile_writer.writerow(['Activity Period','Operating Airline','Operating Airline IATA Code','Published Airline','Published Airline IATA Code','GEO Summary','GEO Region','Activity Type Code','Cargo Type Code','Cargo Aircraft Type','Cargo Weight LBS','Cargo Metric TONS'])\n",
    "for i in documents:\n",
    "    #print(i)\n",
    "    Activity_Period=i['activity_period']\n",
    "    Operating_Airline=i['operating_airline']\n",
    "    Operating_Airline_IATA_Code=i['operating_airline_iata_code']\n",
    "    Published_Airline=i['published_airline']\n",
    "    Published_Airline_IATA_Code=i['published_airline_iata_code']\n",
    "    GEO_Summary=i['geo_summary']\n",
    "    GEO_Region=i['geo_region']\n",
    "    Activity_Type_Code=i['activity_type_code']\n",
    "    Cargo_Type_Code=i['cargo_type_code']\n",
    "    Cargo_Aircraft_Type=i['cargo_aircraft_type']\n",
    "    Cargo_Weight_LBS=i['cargo_weight_lbs']\n",
    "    Cargo_Metric_TONS=i['cargo_metric_tons']\n",
    "   \n",
    "    csv_line = [Activity_Period,Operating_Airline,Operating_Airline_IATA_Code,Published_Airline,Published_Airline_IATA_Code,GEO_Summary,GEO_Region,Activity_Type_Code,Cargo_Type_Code,Cargo_Aircraft_Type,Cargo_Weight_LBS,Cargo_Metric_TONS]\n",
    "    csvfile_writer.writerow(csv_line)\n",
    "csvfile.close()\n",
    "#reading all the data in csv file\n",
    "ATC_df = pd.read_csv(\"air_cargo1.csv\")\n",
    "ATC_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd7b33",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5621d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------Information-----------\")\n",
    "print(ATC_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------Null value-----------\")\n",
    "print(ATC_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6574bf6b",
   "metadata": {},
   "source": [
    "Visualizing the null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc473048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import pandas as pd\n",
    "\n",
    "msno.bar(ATC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the columns as they are not required\n",
    "ATC_df.drop([\"Operating Airline IATA Code\",\"Published Airline IATA Code\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------Null value-----------\")\n",
    "print(ATC_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Description of the dataset\n",
    "ATC_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749f558",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the unique values present\n",
    "print(ATC_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ec1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['GEO Summary','GEO Region','Activity Type Code','Cargo Type Code','Cargo Aircraft Type']\n",
    "for col in columns:\n",
    "    print(f'{col} :-',ATC_df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32449302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts the first 4 characters of the \"Activity_Period\" column, convert to string store in \"Activity_Year\" \n",
    "ATC_df[\"Activity_Year\"]=(ATC_df['Activity Period'].astype(str).str)[:4]\n",
    "ATC_df[\"Activity_Month\"]=(ATC_df['Activity Period'].astype(str).str)[4:]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d6da85c",
   "metadata": {},
   "source": [
    "converting the Activity period format and printing the data range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset activity period to a datetime. \n",
    "ATC_df[\"Activity Period\"] = pd.to_datetime(ATC_df[\"Activity Period\"], format = \"%Y%m\")\n",
    "\n",
    "# print date range\n",
    "print(\"This dataset covers the years from\", ATC_df[\"Activity Period\"].min(),\"to {}.\".format(ATC_df[\"Activity Period\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing the dataset to verify the new columns\n",
    "ATC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1308bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looking at the datatypes\n",
    "ATC_df.dtypes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17e993a3",
   "metadata": {},
   "source": [
    "Looking at the nymerical and categorical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [var for var in ATC_df.columns if ATC_df[var].dtype!='O'] \n",
    "categorical = [var for var in ATC_df.columns if ATC_df[var].dtype == 'O']\n",
    "print(numerical)\n",
    "print(categorical)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e9229",
   "metadata": {},
   "source": [
    "# Adding the dataset into postgresql "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38e597d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "# Connecting to the database\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"postgres\", password=\"test@123\", host=\"35.197.222.181\", port=\"5432\", database=\"dap\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    #Remove previous data\n",
    "    cursor.execute(\"TRUNCATE TABLE ATC_df\")\n",
    "\n",
    "    #Defining the table schema\n",
    "    table_schema = \"CREATE TABLE IF NOT EXISTS ATC_df (\" \\\n",
    "                   \"Activity_Period TEXT,\" \\\n",
    "                   \"Operating_Airline TEXT, \" \\\n",
    "                   \"Published_Airline TEXT, \" \\\n",
    "                   \"Geo_Summary TEXT, \" \\\n",
    "                   \"Geo_Region TEXT, \" \\\n",
    "                   \"Activity_Type_Code TEXT, \" \\\n",
    "                   \"Cargo_Type_Code TEXT, \" \\\n",
    "                   \"Cargo_Aircraft_Type TEXT, \" \\\n",
    "                   \"Cargo_Weight_Lbs TEXT, \" \\\n",
    "                   \"Cargo_Metric_Tons TEXT,\" \\\n",
    "                   \"Activity_Year TEXT,\" \\\n",
    "                   \"Activity_Month TEXT)\"\n",
    "\n",
    "    #Creating the table\n",
    "    cursor.execute(table_schema)\n",
    "    connection.commit()\n",
    "\n",
    "    #Inser data into the table using execute_batch\n",
    "    data = []\n",
    "    for index, row in ATC_df.iterrows():\n",
    "        data.append((\n",
    "            str(row['Activity Period']),\n",
    "            str(row['Operating Airline']),\n",
    "            str(row['Published Airline']),\n",
    "            str(row['GEO Summary']),\n",
    "            str(row['GEO Region']),\n",
    "            str(row['Activity Type Code']),\n",
    "            str(row['Cargo Type Code']),\n",
    "            str(row['Cargo Aircraft Type']),\n",
    "            str(row['Cargo Weight LBS']),\n",
    "            str(row['Cargo Metric TONS']),\n",
    "            str(row['Activity_Year']),\n",
    "            str(row['Activity_Month'])\n",
    "        ))\n",
    "\n",
    "    execute_batch(cursor, \"INSERT INTO ATC_df (Activity_Period, Operating_Airline, Published_Airline, Geo_Summary, Geo_Region, Activity_Type_Code, Cargo_Type_Code, Cargo_Aircraft_Type, Cargo_Weight_Lbs, Cargo_Metric_Tons, Activity_Year, Activity_Month) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", data, page_size=1000)\n",
    "    connection.commit()\n",
    "\n",
    "    print(\"Data uploaded to PostgreSQL successfully.\")\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL:\", error)\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        ATC_DATASET = pd.read_sql('select * from ATC_df', con=connection)\n",
    "        print(\"PostgreSQL connection closed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0254caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ATC_DATASET = pd.read_sql('select * from ATC_df', con=connection)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00167780",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1f8c",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaf9bcc2",
   "metadata": {},
   "source": [
    "Visualizing the number of cargos shipped every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c4fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------Distribution Table of no. of cargos shipped based on year:----------\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the period distribution\n",
    "period_dist = ATC_DATASET['activity_year'].value_counts().sort_index()\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 3))\n",
    "ax.bar(period_dist.index, period_dist.values)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Fig.1: Distribution of Activity Years')\n",
    "\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de764904",
   "metadata": {},
   "source": [
    "Visusualizing the column GEO summary by plotting the distribution of values from the columns 'GEO Summary'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the geo_summary distribution\n",
    "geo_counts = ATC_DATASET['geo_summary'].value_counts()\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "geo_counts.plot(kind='barh', ax=ax)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Geographic Summary')\n",
    "ax.set_title('Fig.2: Distribution of Geographic Summaries')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f20769cf",
   "metadata": {},
   "source": [
    "Visusualizing the column GEO Region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e770999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the value counts of the 'geo_region' column in ATC_DATASET\n",
    "geo_region_counts = ATC_DATASET['geo_region'].value_counts()\n",
    "\n",
    "# Create a pie chart with the value counts\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.pie(geo_region_counts.values, labels=geo_region_counts.index, autopct='%1.1f%%', shadow=True)\n",
    "\n",
    "# Set the title\n",
    "ax.set_title('Fig.3: Distribution of GEO Regions')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b040a3d6",
   "metadata": {},
   "source": [
    "Plotting the distribution of values from the columns 'Activity Type Code', 'Cargo Type Code','Cargo Aircraft Type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure, axes = plt.subplots(1, 3,figsize=(20,5))\n",
    "ATC_DATASET['activity_type_code'].value_counts().plot(ax=axes[0],kind='bar',rot=0,title='Fig.4: Activity Type Code',color='red')\n",
    "ATC_DATASET['cargo_type_code'].value_counts().plot(ax=axes[1],kind='bar',rot=0,title='Fig.5: Cargo Type Code',color='blue')\n",
    "ATC_DATASET['cargo_aircraft_type'].value_counts().plot(ax=axes[2],kind='bar',rot=0,title='Fig.6: Cargo Aircraft Type',color='green')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ce2132d3",
   "metadata": {},
   "source": [
    "Visusualizing the most used airline for shipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['operating_airline'].count() > 100\n",
    "\n",
    "df_filter = ATC_DATASET.groupby(['operating_airline']).filter(filter_func)\n",
    "df_val = df_filter['operating_airline'].value_counts()\n",
    "df_top_10 = df_val[:10]\n",
    "df_others = pd.Series(df_val[10:].sum(), index=['Others'])\n",
    "\n",
    "df_top_10 = pd.concat([df_top_10, df_others])\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#a3a3a3']\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.pie(df_top_10, labels=df_top_10.index, autopct='%1.1f%%',colors=colors)\n",
    "plt.title('FIg.7: Top 10 Airlines used for cargo shipment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0862e594",
   "metadata": {},
   "source": [
    "Visusualization of what percentages of cargo (by weight) is exported and imported via SFO every year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ba059",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Extracting 'Activity Year' and 'Cargo Metric TONS' columns and storing in a new Dataframe\n",
    "cargo=ATC_DATASET[['activity_year','cargo_metric_tons']]\n",
    "#creating a copy of the df\n",
    "cargo_1 = cargo.copy()\n",
    "#Convert the columns to float\n",
    "cargo_1['activity_year'] = cargo_1['activity_year'].astype(float)\n",
    "cargo_1['cargo_metric_tons']=cargo_1['cargo_metric_tons'].astype(float)\n",
    "#Creating two separate dataframes to store international and domestic shipments for every year\n",
    "exports_wt=(cargo_1[(ATC_DATASET['activity_type_code']=='Enplaned') & (ATC_DATASET['geo_summary']=='International')].groupby(['activity_year']).sum()/1000).round(2).rename(columns={\"cargo_metric_tons\":\"Exported Goods(in KiloTonne)\"})\n",
    "\n",
    "imports_wt=(cargo_1[(ATC_DATASET['activity_type_code']=='Deplaned') & (ATC_DATASET['geo_summary']=='International')].groupby(['activity_year']).sum()/1000).round(2).rename(columns={\"cargo_metric_tons\":\"Imported Goods(in KiloTonne)\"})\n",
    "\n",
    "#Creating a variable total_ship to store total no. of shipments for every year\n",
    "total_ship=exports_wt['Exported Goods(in KiloTonne)']+ imports_wt['Imported Goods(in KiloTonne)']\n",
    "\n",
    "#Creating a variable int_ship_percent for calculating and storing the % of international shipments for every year\n",
    "export_percent=pd.DataFrame()\n",
    "export_percent['Export %']=(((exports_wt['Exported Goods(in KiloTonne)']/total_ship)*100).round(2))\n",
    "import_percent=pd.DataFrame()\n",
    "import_percent['Import %']=100-export_percent\n",
    "int_ship_avg=export_percent.mean()\n",
    "diff_percentage=pd.DataFrame(data=export_percent['Export %']-import_percent['Import %'], columns=['%Difference between Qt. exported vs imported'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de3fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Plot line chart for exports weight\n",
    "axs[0, 0].plot(exports_wt.index, exports_wt, color='green')\n",
    "axs[0, 0].set_title('Fig.8: Total weight of goods Exported')\n",
    "axs[0, 0].set_xlabel('Year')\n",
    "axs[0, 0].set_ylabel('Weight (in KiloTonne)')\n",
    "\n",
    "# Plot line chart for imports weight\n",
    "axs[0, 1].plot(imports_wt.index, imports_wt, color='red')\n",
    "axs[0, 1].set_title('Fig.9: Total weight of goods Imported')\n",
    "axs[0, 1].set_xlabel('Year')\n",
    "axs[0, 1].set_ylabel('Weight (in KiloTonne)')\n",
    "\n",
    "# Plot line chart for difference in percentage\n",
    "axs[1, 0].plot(diff_percentage.index, diff_percentage, color='blue')\n",
    "axs[1, 0].set_title('Fig.10: % Difference between quantity exported vs imported')\n",
    "axs[1, 0].set_xlabel('Year')\n",
    "axs[1, 0].set_ylabel('Percentage (%)')\n",
    "\n",
    "# Plot stacked bar chart for exports and imports\n",
    "axs[1, 1].bar(imports_wt.index, imports_wt['Imported Goods(in KiloTonne)'], label='Imports', color='red')\n",
    "axs[1, 1].bar(exports_wt.index, exports_wt['Exported Goods(in KiloTonne)'], label='Exports', color='green')\n",
    "\n",
    "axs[1, 1].set_title('Fig.11: Total weight of goods Exported vs Imported')\n",
    "axs[1, 1].set_xlabel('Year')\n",
    "axs[1, 1].set_ylabel('Weight (in KiloTonne)')\n",
    "axs[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3f8da1cb",
   "metadata": {},
   "source": [
    "visusualization of operating air and published airline with cargo weight and geo summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = ATC_DATASET\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(df, x='operating_airline', y='published_airline', color='geo_summary', hover_name='cargo_weight_lbs', title='Fig.12: Operating airline to published airline')\n",
    "\n",
    "# Set the figure size and margins\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=50, r=50, b=100, t=100, pad=4)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f19bc5b2",
   "metadata": {},
   "source": [
    "Visusualizing the import and export trends with respect to every region over the years in via San Francisco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20971e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating filters to select only the export and imports shipment records separately\n",
    "export_filter=(ATC_DATASET['geo_summary']=='International') & (ATC_DATASET['activity_type_code']=='Enplaned')\n",
    "import_filter=(ATC_DATASET['geo_summary']=='International') & (ATC_DATASET['activity_type_code']=='Deplaned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the above filters to create a subset of data containing select details of export and imports shipment records\n",
    "exp=ATC_DATASET[export_filter][['activity_year','geo_region','cargo_metric_tons']]\n",
    "imp=ATC_DATASET[import_filter][['activity_year','geo_region','cargo_metric_tons']]\n",
    "#converting the columns into float type\n",
    "exp['activity_year']=exp['activity_year'].astype(float)\n",
    "exp['cargo_metric_tons']=exp['cargo_metric_tons'].astype(float)\n",
    "imp['activity_year']=imp['activity_year'].astype(float)\n",
    "imp['cargo_metric_tons']=imp['cargo_metric_tons'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c05a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a separate the list of regions \n",
    "regions=exp['geo_region'].unique()\n",
    "    #print(regions)\n",
    "    \n",
    "#Creating two separate empty dataframes for storing the value of weights of exports and imports separately for every region\n",
    "export_summary=pd.DataFrame()\n",
    "import_summary=pd.DataFrame()\n",
    "#Evaluating the export and import % for every region and updating respective values in export_summary and import_summary\n",
    "for val in regions:\n",
    "    export_summary[val]=(exp[exp['geo_region']==val][['activity_year','cargo_metric_tons']].groupby('activity_year').sum()).round(2)\n",
    "    import_summary[val]=(imp[imp['geo_region']==val][['activity_year','cargo_metric_tons']].groupby('activity_year').sum()).round(2)  \n",
    "\n",
    "\n",
    "#Checking if there are any NaN Values in the summary tables\n",
    "print(\"Export Table : \")\n",
    "print(export_summary)\n",
    "print(\"Import Table : \")\n",
    "print(import_summary)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dce94c33",
   "metadata": {},
   "source": [
    "From the above summary we can see that there are some NaN values present, these NaN values indicates that those countries did not have any import or export activity from SFA. Replacing the NaN values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_summary.fillna(0,inplace=True)\n",
    "import_summary.fillna(0,inplace=True)\n",
    "\n",
    "#Adding a new column in each of the summary table named 'Total Exports' and 'Total Imports',respectively. Each row stores the sum total of the weights exported/imported for that particular year\n",
    "export_summary['Total Exports']=export_summary.agg(\"sum\", axis=\"columns\")\n",
    "import_summary['Total Imports']=import_summary.agg(\"sum\", axis=\"columns\")\n",
    "export_summary['Total Exports'].fillna(0,inplace=True)\n",
    "import_summary['Total Imports'].fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating separate dataframes for storing the % values of yearly export and imports for every country\n",
    "import_percent_reg=pd.DataFrame()\n",
    "export_percent_reg=pd.DataFrame()\n",
    "for val in regions:\n",
    "    import_percent_reg[val]=((import_summary[val]/import_summary['Total Imports'])*100).round(2)\n",
    "    export_percent_reg[val]=((export_summary[val]/export_summary['Total Exports'])*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf84b21",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "diff_perc_reg=export_percent_reg-import_percent_reg\n",
    "diff_perc_reg.plot(title='Fig.13 % Difference (Qt) in Exported vs Imported Cargo ',figsize=(20,10))\n",
    "\n",
    "#Plotting the yearly export vs import % separately for every country\n",
    "figure,axes=plt.subplots(4,2,figsize=(20,20))\n",
    "i=0\n",
    "j=0\n",
    "count=14\n",
    "for val in regions:\n",
    "    \n",
    "    export_percent_reg[val].plot(ax=axes[i][j],kind='line',rot=0,color='green',xlabel='Year',grid=True,title='Fig:'+str(count)+' '+val, ylabel='Percentage (%)')\n",
    "    import_percent_reg[val].plot(ax=axes[i][j],kind='line',rot=0,color='red',xlabel='Year',grid=True)\n",
    "    if i<3:\n",
    "        i=i+1\n",
    "        \n",
    "    else:\n",
    "        j=1\n",
    "        i=0\n",
    "    count+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
