{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78e58799",
   "metadata": {},
   "source": [
    "# Importing the Data for Air Traffic Cargo Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0312e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_call = \"https://data.sfgov.org/api/views/u397-j8nr/rows.json?accessType=DOWNLOAD\"\n",
    "\n",
    "# Get the JSON data from the API\n",
    "response = requests.get(api_call)\n",
    "data = response.json()\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd9e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data rows from the JSON data\n",
    "rows = data['data']\n",
    "\n",
    "# Extract the column headers from the JSON data\n",
    "headers = [col['fieldName'] for col in data['meta']['view']['columns']]\n",
    "\n",
    "headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bbe32cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the metadata fields from the rows\n",
    "filtered_rows = []\n",
    "for row in rows:\n",
    "    filtered_row = {headers[idx]: cell for idx, cell in enumerate(row) if not headers[idx].startswith(':')}\n",
    "\n",
    "    filtered_rows.append(filtered_row)\n",
    "\n",
    "# Create a new JSON object without the metadata fields\n",
    "filtered_data = {'data': filtered_rows}\n",
    "filtered_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc114bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = filtered_data['data']\n",
    "final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89614e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "import requests\n",
    "#from pymongo import MongoClient \n",
    "#pymongo to connect to an existing document collection\n",
    "from pymongo import MongoClient, InsertOne\n",
    "\n",
    "import requests \n",
    "client = MongoClient('mongodb+srv://arun:nLmzJ6cxxu@cluster0.bqu9sx9.mongodb.net/?retryWrites=true&w=majority')\n",
    "#client = MongoClient('mongodb://localhost:27017')\n",
    "db = client.Test\n",
    "collection = db.test\n",
    "d = collection.delete_many({})\n",
    "print(d.deleted_count, \" documents deleted.\")\n",
    "#test123harini\n",
    "#test123abhijith\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa64a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "document=collection.insert_many(final_data)\n",
    "document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16eee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint as pp\n",
    "for Air_cargo in db.test.find():\n",
    "    pp.pprint(Air_cargo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509bfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetching a database in MongoDB\n",
    "import pandas as pd\n",
    "ATC_df = pd.DataFrame(list(collection.find())) #placing all in one DF\n",
    "ATC_df=ATC_df.drop(['_id'], axis=1)\n",
    "ATC_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0edd7b33",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5621d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"-----------Information-----------\")\n",
    "print(ATC_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb0201c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------Null value-----------\")\n",
    "print(ATC_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Calculate the percentage of missing values for each column\n",
    "missing_pct = ATC_df.isnull().mean() * 100\n",
    "\n",
    "# Create a bar chart of the percentage of missing values for each column\n",
    "plt.bar(missing_pct.index, missing_pct.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel(\"Percentage of missing values\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc473048",
   "metadata": {},
   "outputs": [],
   "source": [
    "import missingno as msno\n",
    "import pandas as pd\n",
    "\n",
    "msno.bar(ATC_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c90c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the columns as they are not required\n",
    "ATC_df.drop([\"operating_airline_iata_code\",\"published_airline_iata_code\"],axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3f233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"----------Null value-----------\")\n",
    "print(ATC_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3c27a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2749f558",
   "metadata": {},
   "source": [
    "# DATA TRANSFORMATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961a2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ATC_df.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3ec1af",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns=['geo_summary','geo_region','activity_type_code','cargo_type_code','cargo_aircraft_type']\n",
    "for col in columns:\n",
    "    print(f'{col} :-',ATC_df[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32449302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracts the first 4 characters of the \"Activity_Period\" column, convert to string store in \"Activity_Year\" \n",
    "ATC_df[\"Activity_Year\"]=(ATC_df['activity_period'].astype(str).str)[:4]\n",
    "ATC_df[\"Activity_Month\"]=(ATC_df['activity_period'].astype(str).str)[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ded869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset activity period to a datetime. \n",
    "ATC_df[\"activity_period\"] = pd.to_datetime(ATC_df[\"activity_period\"], format = \"%Y%m\")\n",
    "\n",
    "# print date range\n",
    "print(\"This dataset covers the years from\", ATC_df[\"activity_period\"].min(),\"to {}.\".format(ATC_df[\"activity_period\"].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce5fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1308bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ee58ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical = [var for var in ATC_df.columns if ATC_df[var].dtype!='O'] #check numerical columns\n",
    "categorical = [var for var in ATC_df.columns if ATC_df[var].dtype == 'O']\n",
    "print(numerical)\n",
    "print(categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6803aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5270fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import Error\n",
    "\n",
    "# Connect to the database\n",
    "try:\n",
    "    connection = psycopg2.connect(user=\"postgres\", password=\"test@123\", host=\"localhost\", port=\"5432\", database=\"Test\")\n",
    "    cursor = connection.cursor()\n",
    "\n",
    "    # Define the table schema\n",
    "    table_schema = \"CREATE TABLE IF NOT EXISTS ATC_df (\" \\\n",
    "                   \"Activity_Period TEXT,\" \\\n",
    "                   \"Operating_Airline TEXT, \" \\\n",
    "                   \"Published_Airline TEXT, \" \\\n",
    "                   \"Geo_Summary TEXT, \" \\\n",
    "                   \"Geo_Region TEXT, \" \\\n",
    "                   \"Activity_Type_Code TEXT, \" \\\n",
    "                   \"Cargo_Type_Code TEXT, \" \\\n",
    "                   \"Cargo_Aircraft_Type TEXT, \" \\\n",
    "                   \"Cargo_Weight_Lbs TEXT, \" \\\n",
    "                   \"Cargo_Metric_Tons TEXT,\" \\\n",
    "                   \"Activity_Year TEXT,\" \\\n",
    "                   \"Activity_Month TEXT)\"\n",
    "\n",
    "    # Create the table\n",
    "    cursor.execute(table_schema)\n",
    "    connection.commit()\n",
    "\n",
    "    # Insert data into the table\n",
    "    for index, row in ATC_df.iterrows():\n",
    "        insert_query = \"INSERT INTO ATC_df (Activity_Period, Operating_Airline, \" \\\n",
    "                       \"Published_Airline, Geo_Summary, Geo_Region, Activity_Type_Code, \" \\\n",
    "                       \"Cargo_Type_Code, Cargo_Aircraft_Type, Cargo_Weight_Lbs, Cargo_Metric_Tons, \" \\\n",
    "                       \"Activity_Year, Activity_Month) \" \\\n",
    "                       \"VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\"\n",
    "\n",
    "        values = (str(row['activity_period']),\n",
    "                  str(row['operating_airline']),\n",
    "                  str(row['published_airline']),\n",
    "                  str(row['geo_summary']),\n",
    "                  str(row['geo_region']),\n",
    "                  str(row['activity_type_code']),\n",
    "                  str(row['cargo_type_code']),\n",
    "                  str(row['cargo_aircraft_type']),\n",
    "                  str(row['cargo_weight_lbs']),\n",
    "                  str(row['cargo_metric_tons']),\n",
    "                  str(row['Activity_Year']),\n",
    "                  str(row['Activity_Month']))\n",
    "\n",
    "        cursor.execute(insert_query, values)\n",
    "\n",
    "    connection.commit()\n",
    "    print(\"Data uploaded to PostgreSQL successfully.\")\n",
    "\n",
    "except (Exception, Error) as error:\n",
    "    print(\"Error while connecting to PostgreSQL:\", error)\n",
    "\n",
    "finally:\n",
    "    if connection:\n",
    "        cursor.close()\n",
    "        print(\"PostgreSQL connection closed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0254caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "ATC_DATASET = pd.read_sql('select * from ATC_df', con=connection)\n",
    "\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00167780",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ce1f8c",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145c4fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-------Distribution Table of no. of cargos shipped based on year:----------\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate the period distribution\n",
    "period_dist = ATC_DATASET['activity_year'].value_counts().sort_index()\n",
    "\n",
    "# Create a bar plot\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.bar(period_dist.index, period_dist.values)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Period')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Activity Years')\n",
    "\n",
    "# Rotate x-axis labels if needed\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce52a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Calculate the geo_summary distribution\n",
    "geo_counts = ATC_DATASET['geo_summary'].value_counts()\n",
    "\n",
    "# Create a horizontal bar plot\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "geo_counts.plot(kind='barh', ax=ax)\n",
    "\n",
    "# Set axis labels and title\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Geographic Summary')\n",
    "ax.set_title('Distribution of Geographic Summaries')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61406f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ATC_DATASET['geo_region'].value_counts().plot(kind='bar',rot=0,title='GEO Region',color='red',figsize=(15,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8120aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "figure, axes = plt.subplots(1, 3,figsize=(20,5))\n",
    "ATC_DATASET['activity_type_code'].value_counts().plot(ax=axes[0],kind='bar',rot=0,title='Activity Type Code',color='red')\n",
    "ATC_DATASET['cargo_type_code'].value_counts().plot(ax=axes[1],kind='bar',rot=0,title='Cargo Type Code',color='blue')\n",
    "ATC_DATASET['cargo_aircraft_type'].value_counts().plot(ax=axes[2],kind='bar',rot=0,title='Cargo Aircraft Type',color='green')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0550a094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_func(x):\n",
    "    return x['operating_airline'].count() > 100\n",
    "\n",
    "df_filter = ATC_DATASET.groupby(['operating_airline']).filter(filter_func)\n",
    "df_val = df_filter['operating_airline'].value_counts()\n",
    "df_top_10 = df_val[:10]\n",
    "df_others = pd.Series(df_val[10:].sum(), index=['Others'])\n",
    "\n",
    "df_top_10 = pd.concat([df_top_10, df_others])\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b', '#e377c2', '#7f7f7f', '#bcbd22', '#17becf', '#a3a3a3']\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "plt.pie(df_top_10, labels=df_top_10.index, autopct='%1.1f%%',colors=colors)\n",
    "plt.title('Top 10 Airlines used for cargo shipment')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c0ba059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting 'Activity Year' and 'Cargo Metric TONS' columns and storing in a new Dataframe\n",
    "cargo=ATC_DATASET[['activity_year','cargo_metric_tons']]\n",
    "#creating a copy of the df\n",
    "cargo_1 = cargo.copy()\n",
    "#Convert the columns to float\n",
    "cargo_1['activity_year'] = cargo_1['activity_year'].astype(float)\n",
    "cargo_1['cargo_metric_tons']=cargo_1['cargo_metric_tons'].astype(float)\n",
    "#Creating two separate dataframes to store international and domestic shipments for every year. Each will be a subset of 'act' dataframe\n",
    "exports_wt=(cargo_1[(ATC_DATASET['activity_type_code']=='Enplaned') & (ATC_DATASET['geo_summary']=='International')].groupby(['activity_year']).sum()/1000).round(2).rename(columns={\"cargo_metric_tons\":\"Exported Goods(in KiloTonne)\"})\n",
    "\n",
    "imports_wt=(cargo_1[(ATC_DATASET['activity_type_code']=='Deplaned') & (ATC_DATASET['geo_summary']=='International')].groupby(['activity_year']).sum()/1000).round(2).rename(columns={\"cargo_metric_tons\":\"Imported Goods(in KiloTonne)\"})\n",
    "\n",
    "#Step C-1.3: Creating a variable total_ship to store total no. of shipments for every year\n",
    "total_ship=exports_wt['Exported Goods(in KiloTonne)']+ imports_wt['Imported Goods(in KiloTonne)']\n",
    "\n",
    "#Step C-1.4: Creating a variable int_ship_percent for calculating and storing the % of international shipments for every year\n",
    "export_percent=pd.DataFrame()\n",
    "export_percent['Export %']=(((exports_wt['Exported Goods(in KiloTonne)']/total_ship)*100).round(2))\n",
    "import_percent=pd.DataFrame()\n",
    "import_percent['Import %']=100-export_percent\n",
    "int_ship_avg=export_percent.mean()\n",
    "diff_percentage=pd.DataFrame(data=export_percent['Export %']-import_percent['Import %'], columns=['%Difference between Qt. exported vs imported'])\n",
    "\n",
    "#Step C-1.5: Plotting int_ship variable and the int_ship_percent variable together\n",
    "figure,axes=plt.subplots(1,2,figsize=(20,5))\n",
    "exports_wt.plot(ax=axes[0],kind='line',rot=0,color='green',title='Fig 1.1: Total Wt. of goods Exported vs Imported',grid=True,xlabel='Year',ylabel='Wt.(in KiloTonne)')\n",
    "imports_wt.plot(ax=axes[0],kind='line',rot=0,color='red',xlabel='Year',grid=True)\n",
    "\n",
    "diff_percentage.plot(ax=axes[1],kind='line',rot=0,color='red',grid=True,title='Fig 1.2: %Difference between Qt. exported vs imported',xlabel='Year',ylabel='Percentage (%)',legend=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1f7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Load the data\n",
    "df = ATC_DATASET\n",
    "\n",
    "# Create a scatter plot\n",
    "fig = px.scatter(df, x='operating_airline', y='published_airline', color='geo_summary', hover_name='cargo_weight_lbs', title='Operating airline to published airline')\n",
    "\n",
    "# Set the figure size and margins\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=800,\n",
    "    height=600,\n",
    "    margin=dict(l=50, r=50, b=100, t=100, pad=4)\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20971e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating filters to select only the export and imports shipment records separately\n",
    "export_filter=(ATC_DATASET['geo_summary']=='International') & (ATC_DATASET['activity_type_code']=='Enplaned')\n",
    "import_filter=(ATC_DATASET['geo_summary']=='International') & (ATC_DATASET['activity_type_code']=='Deplaned')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10f9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the above filters to create a subset of data containing select details of export and imports shipment records\n",
    "exp=ATC_DATASET[export_filter][['activity_year','geo_region','cargo_metric_tons']]\n",
    "imp=ATC_DATASET[import_filter][['activity_year','geo_region','cargo_metric_tons']]\n",
    "#converting the columns into float type\n",
    "exp['activity_year']=exp['activity_year'].astype(float)\n",
    "exp['cargo_metric_tons']=exp['cargo_metric_tons'].astype(float)\n",
    "imp['activity_year']=imp['activity_year'].astype(float)\n",
    "imp['cargo_metric_tons']=imp['cargo_metric_tons'].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c05a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a separate the list of regions \n",
    "regions=exp['geo_region'].unique()\n",
    "    #print(regions)\n",
    "    \n",
    "#Creating two separate empty dataframes for storing the value of weights of exports and imports separately for every region\n",
    "export_summary=pd.DataFrame()\n",
    "import_summary=pd.DataFrame()\n",
    "#Evaluating the export and import % for every region and updating respective values in export_summary and import_summary\n",
    "for val in regions:\n",
    "    export_summary[val]=(exp[exp['geo_region']==val][['activity_year','cargo_metric_tons']].groupby('activity_year').sum()).round(2)\n",
    "    import_summary[val]=(imp[imp['geo_region']==val][['activity_year','cargo_metric_tons']].groupby('activity_year').sum()).round(2)  \n",
    "\n",
    "\n",
    "    #Checking if there are any NaNValues in the summary tables\n",
    "print('============')\n",
    "print(\"Export Table : \")\n",
    "print(export_summary)\n",
    "print('============')\n",
    "print(\"Import Table : \")\n",
    "print(import_summary)\n",
    "print('============')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0065164e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_summary.fillna(0,inplace=True)\n",
    "import_summary.fillna(0,inplace=True)\n",
    "\n",
    "#Adding a new column in each of the summary table named 'Total Exports' and 'Total Imports',respectively. Each row stores the sum total of the weights exported/imported for that particular year\n",
    "export_summary['Total Exports']=export_summary.agg(\"sum\", axis=\"columns\")\n",
    "import_summary['Total Imports']=import_summary.agg(\"sum\", axis=\"columns\")\n",
    "export_summary['Total Exports'].fillna(0,inplace=True)\n",
    "import_summary['Total Imports'].fillna(0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc52a7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating separate dataframes for storing the % values of yearly export and imports for every country\n",
    "import_percent_reg=pd.DataFrame()\n",
    "export_percent_reg=pd.DataFrame()\n",
    "for val in regions:\n",
    "    import_percent_reg[val]=((import_summary[val]/import_summary['Total Imports'])*100).round(2)\n",
    "    export_percent_reg[val]=((export_summary[val]/export_summary['Total Exports'])*100).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf84b21",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "diff_perc_reg=export_percent_reg-import_percent_reg\n",
    "diff_perc_reg.plot(title='Fig.1 % Difference (Qt) in Exported vs Imported Cargo ',figsize=(20,10))\n",
    "\n",
    "#Step C-2.11: Plotting the yearly export vs import % separately for every country\n",
    "figure,axes=plt.subplots(4,2,figsize=(20,20))\n",
    "i=0\n",
    "j=0\n",
    "count=2\n",
    "for val in regions:\n",
    "    \n",
    "    export_percent_reg[val].plot(ax=axes[i][j],kind='line',rot=0,color='green',xlabel='Year',grid=True,title='Fig:'+str(count)+' '+val, ylabel='Percentage (%)')\n",
    "    import_percent_reg[val].plot(ax=axes[i][j],kind='line',rot=0,color='red',xlabel='Year',grid=True)\n",
    "    if i<3:\n",
    "        i=i+1\n",
    "        \n",
    "    else:\n",
    "        j=1\n",
    "        i=0\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cc7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
